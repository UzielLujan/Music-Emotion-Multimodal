# Gu铆a de Transici贸n: Fase 2 (Extracci贸n Distribuida y Procesamiento)

**Fecha:** Noviembre 2025  
**Contexto:** Migraci贸n del Pipeline FMA (Legacy) al Pipeline V2 (Spotify/Genius/YouTube).

---

## 1. 驴Por qu茅 cambiamos todo?

El dataset original (FMA) presentaba un problema cr铆tico: la intersecci贸n entre "Audio Disponible" + "Idioma Ingl茅s" + "Etiquetas Emocionales" era demasiado peque帽a (< 2,000 muestras) y de hecho se volvi贸 cero en cuanto se intentaron recuperar sus letras con Genius.

**La Nueva Estrategia (Pipeline V2):**
En lugar de filtrar lo que hay (buscando datos que cumplieran con todas las condiciones), hemos construido nuestro propio dataset desde cero:
1.  **Semillas:** 30,000+ canciones extra铆das de Kaggle (Spotify Tracks), balanceadas por cuadrantes emocionales (Happy, Sad, Angry, Relaxed).
2.  **Letras:** Scrapeadas via Genius API (filtrando instrumentales e idioma no-ingl茅s).
3.  **Audio:** Descarga directa desde YouTube.

**Estado Actual:**
Tenemos un archivo maestro limpio (`metadata_step2_lyrics_clean.csv`) con **~6,500 canciones** perfectamente etiquetadas y con letra. Ahora falta terminar de descargar los audios.

---

## 2. Configuraci贸n del Entorno (CRTICO 锔)

Para que el nuevo pipeline funcione, las dependencias han cambiado significativamente (Python 3.11, soporte nativo de tipos, librer铆as de audio modernas).

**Acci贸n Requerida:**
Por favor, elimina tu entorno anterior y cr茅alo de nuevo usando el archivo `environment.yaml` actualizado en el repositorio.

```bash
# 1. Desactivar y eliminar el viejo
conda deactivate
conda remove --name mem-env --all

# 2. Crear el nuevo (Asegura tener el environment.yaml actualizado)
conda env create -f environment.yaml

# 3. Activar
conda activate mem-env
```
## 3. Estrategia de descarga distribuida ("Divide y Vencer谩s")

YouTube bloquea temporalmente las IPs que descargan demasiado r谩pido. Para evitar esto y acelerar el proceso, dividiremos la carga de trabajo en dos mitades paralelas.

**Paso A: Generar los archivos divididos**

Uzi ejecutar谩 el script de divisi贸n que genera dos archivos en `data/raw_v2/`:

- `metadata_part_uzi.csv` (Primera mitad)

- `metadata_part_brenda.csv` (Segunda mitad)

**Paso B: Tu Misi贸n de Descarga**

1. Abre el archivo src/ExtractDataV2/main.py.

2. Busca la l铆nea donde se define `CSV_STEP2` dentro de `src/ExtractDataV2/main.py` y modif铆cala para apuntar a tu parte:

    ```bash
    # --- EN main.py ---
    # CSV_STEP2 = RAW_V2_DIR / "metadata_step2_lyrics_clean.csv"  <-- COMENTAR ESTA
    CSV_STEP2 = RAW_V2_DIR / "metadata_part_brenda.csv"           # <-- USAR ESTA
    ```
3. Ejecuta el pipeline de descarga:

    ```bash
    python src/ExtractDataV2/main.py
    ```
4. El script saltar谩 autom谩ticamente los Pasos 1 y 2, e iniciar谩 la descarga de audios en el Paso 3.

**Nota**: Si YouTube te bloquea (Error "Sign in to confirm..."), det茅n el script, cambia tu IP (reinicia m贸dem o usa datos) y vuelve a intentar. **El script es incremental, no perder谩s progreso**.

## 4. Arquitectura de la Fase 2: Procesamiento (ProcessData)

Una vez tengamos los audios, entraremos a la fase de **Ingenier铆a de Caracter铆sticas**. Hemos dise帽ado una estructura modular para trabajar en paralelo sin conflictos.

**Estructura de Carpetas de ProcessData:**

```bash
src/ProcessData/
 audio/            # (Responsable: Uzi) - Recorte, Espectrogramas, HSFs
 text/             # (Responsable: Brenda) - Limpieza, TF-IDF, Embeddings
 utils/            # Funciones compartidas (Carga de archivos, Alineaci贸n)
```

**Tu Misi贸n de Desarrollo (Rama de Texto):**

Mientras Uzi se encarga de procesar los audios (cuando finalmente se descarguen todos), t煤 estar谩s a cargo de la inteligencia del Texto. Necesitamos que desarrolles los siguientes m贸dulos dentro de `src/ProcessData/text/`:

1. `cleaning.py`:

- Funci贸n que reciba el string raw de Genius.

- Elimine etiquetas como [Chorus], [Verse 1].

- Elimine caracteres especiales y normalice (lowercase).

2. `embeddings.py`:

- Esta es la pieza clave. Necesitamos una funci贸n que cargue un modelo Transformer (`BERT`) y convierta el texto limpio en un tensor/vector.

- Tip: Dise帽a la funci贸n para que reciba el texto y devuelva un `numpy array` (`.npy`).

## 5. Filosof铆a de C贸digo para la Fase 2 (Best Practices) 
Dado que vamos a integrar tu c贸digo de texto con el pipeline de audio para correrlo masivamente en una GPU, necesitamos seguir ciertas pautas de ingenier铆a de software para que todo encaje como piezas de LEGO.

1. **Adi贸s a los Notebooks (.ipynb) en Producci贸n**

- Los notebooks son geniales para explorar, pero para el pipeline final necesitamos archivos `.py` pues los archivos `.py` se pueden importar entre s铆. Un notebook no.

- **Flujo de trabajo**: Prototipa en Colab/Jupyter Notebooks si quieres, pero el c贸digo final debe estar limpio en `src/ProcessData/text/tus_scripts.py`.

2. **Funciones Puras (Modularidad)**

- Evita escribir c贸digo que se ejecute "suelto" al inicio del archivo. Todo debe estar dentro de funciones.
- De esta forma, el pipeline puede llamar a tus funciones cuando lo necesite. Por ejemplo, Uzi puede importar `from text.cleaning import limpiar_texto` y aplicarlo a las 6,000 canciones autom谩ticamente.

3. **Rutas Relativas (Pathlib) y Configuraci贸n Centralizada**

- Evita usar rutas absolutas como `C:/Users/Brenda/....` Eso romper谩 el c贸digo en la otra computadora.

- Usa siempre `pathlib` basado en la ra铆z del proyecto (ya configurado en `main.py`).

4. **Preparaci贸n para GPU (C贸digo y Dependencias)**

- Parametrizaci贸n del Device: Cuando dise帽es las funciones para BERT/Embeddings, evita "hardcodear" el uso de CPU. Estructura tu funci贸n para aceptar un par谩metro device:

```Python
def get_embedding(text, model, device='cpu'):
    # El orquestador le pasar谩 'cuda' cuando Uzi corra el script en la GPU
    # Ejemplo interno: inputs = tokenizer(text, ...).to(device)
    pass
```
- **Verificaci贸n de Dependencias (CUDA)**: El archivo `environment.yaml` actual instala transformers, lo cual usualmente instala torch (PyTorch) como dependencia. Sin embargo, a veces los gestores de paquetes descargan la versi贸n **CPU-only** por defecto para ahorrar espacio.

- **Tu Misi贸n**: Investiga y verifica si necesitamos especificar una versi贸n de PyTorch compatible con CUDA (ej. pytorch-cuda en Conda).

- **Acci贸n**: Si encuentras que se necesita una instalaci贸n espec铆fica para habilitar la GPU, por favor actualiza el `environment.yaml` o agrega una nota en el c贸digo, no solo con esa dependencia en especifico, sino con cualquier otra que sea necesaria. Esto es vital para que Uzi pueda correr el pipeline completo en GPU sin problemas con el entorno adecuado.

## 6. Eso es todo por ahora!